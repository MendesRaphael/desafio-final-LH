import pandas as pd 

import numpy as np

import matplotlib.pyplot as plt #bibliotecas para visualizações
import seaborn as sns

from datasetsforecast.hierarchical import HierarchicalData
from hierarchicalforecast.core import HierarchicalReconciliation
from hierarchicalforecast.methods import  BottomUp, TopDown, MiddleOut, MinTrace, ERM
from hierarchicalforecast.evaluation import HierarchicalEvaluation
from hierarchicalforecast.utils import aggregate

from statsforecast.core import StatsForecast
from statsforecast.models import AutoARIMA, Naive
import pyarrow

from datetime import datetime

from sklearn.metrics import mean_squared_error as mse


pd.options.display.width = 0
pd.set_option('display.max_rows', 500)



# reading the dataset using read_csv
df = pd.read_csv("tabela_ds_agrupada.csv", 
                 parse_dates=True
                 #,index_col="orderdate"
                )
 
# displaying the first five rows of dataset
df.head()


df['name_store'] = df['name_store'].fillna('online')





print('As datas encontram-se no intervalo de', df.orderdate.min(), 'até', df.orderdate.max())


df = df[df['orderdate']>='2012-01-01']





print(df['orderdate'].min())
print(df['orderdate'].max())


# Agrupa por 'productmodel_name' e soma 'total_qtd_product'
df_total = df.groupby('productmodel_name')['total_qtd_product'].sum()

# Ordena o DataFrame pela soma
df_total = df_total.sort_values(ascending=False)

df_total






df.shape


to_remove = ['Rear Brakes'
             ,'All-Purpose Bike Stand'
             ,'HL Touring Handlebars'
             ,'LL Road Handlebars'
             ,'Touring Pedal'
             ,'HL Road Seat/Saddle'
             ,'LL Touring Seat/Saddle'
             ,'ML Touring Seat/Saddle'
             ,'ML Crankset'
             ,'LL Touring Handlebars'
             ,'LL Road Seat/Saddle'  
            ] 

# Em seguida, remova essas linhas do DataFrame
df = df[~df['productmodel_name'].isin(to_remove)]


df.shape







df['name_store'][df['countryregioncode']=='United States'].value_counts()


df['name_store'][df['countryregioncode']=='others'].value_counts()


# Agrupa por 'productmodel_name' e soma 'total_qtd_product'
df_total = df.groupby('name_store')['total_qtd_product'].sum()

# Ordena o DataFrame pela soma
df_total = df_total.sort_values(ascending=False)

df_total



# Cria uma nova coluna que é o produto de 'total_qtd_product' e 'unitprice_product'
df['total_value'] = df['total_qtd_product'] * df['unitprice_product']

# Agrupa por 'productmodel_name' e soma 'total_value'
df_total_value = df.groupby('name_store')['total_value'].sum().round(2)

# Ordena o DataFrame pela soma
df_total_value = df_total_value.sort_values(ascending=False)

df_total_value


df.shape





to_remove = ['Active Systems', 'Handy Bike Services','Nearest Bike Store']

# Em seguida, remova essas linhas do DataFrame
df = df[~df['name_store'].isin(to_remove)]


df.shape


df['name_store'].unique()


df['name_store'] = df['name_store'].str.replace(" ", "_")


df['name_store'].unique()


df.info()


#copia o df original
df_aux = df.copy()

df_aux['orderdate'] = pd.to_datetime(df_aux['orderdate'])
df_aux.set_index('orderdate', inplace=True)
# Crie uma nova coluna 'ano-mês' no DataFrame
df_aux['ano_mes'] = df_aux.index.to_period('M')

# Filtra os dados para a loja 'online'
df_online = df_aux[df_aux['name_store'] == 'online']

# Filtra os dados para todas as outras lojas
df_outros = df_aux[df_aux['name_store'] != 'online']

# Agrupa os dados por 'ano-mês' e soma as vendas
df_total_online = df_online.groupby('ano_mes')['total_qtd_product'].sum()
df_total_outros = df_outros.groupby('ano_mes')['total_qtd_product'].sum()

# Cria o gráfico para a loja 'online'
df_total_online.plot(kind='line', figsize=(18,2))
df_total_online.plot(marker='x', linestyle='', color='red')
plt.title('Totais absolutos de vendas para a loja online por mês')
plt.xlabel('Mês')
plt.ylabel('Total de vendas')
plt.show()

# Cria o gráfico para todas as outras lojas
df_total_outros.plot(kind='line', figsize=(18,2))
df_total_outros.plot(marker='x', linestyle='', color='red')
plt.title('Totais absolutos de vendas para todas as lojas físicas por mês')
plt.xlabel('Mês')
plt.ylabel('Total de vendas')
plt.show()



print("Hierarquia das lojas")
for store in np.sort(df['name_store'].unique()):
    print("├──>",store)



# Obtenha a lista de todas as lojas únicas
lojas = df_aux['name_store'].unique()

# Para cada loja, crie um gráfico separado
for loja in lojas:
    # Filtra os dados para a loja atual
    df_loja = df_aux[df_aux['name_store'] == loja]
    
    # Agrupa os dados por 'ano-mês' e soma as vendas
    df_grouped = df_loja.groupby('ano_mes')['total_qtd_product'].sum()
    
    # Cria o gráfico
    df_grouped.plot(kind='line', figsize=(20,3))

    # Adiciona marcações com 'x' vermelho nos pontos de dados
    df_grouped.plot(marker='x', linestyle='', color='red')
    
    # Adiciona os valores para cada ponto
    for x, y in zip(df_grouped.index, df_grouped.values):
        plt.text(x, y, str(y), color="blue", fontsize=8)
    
    plt.title(f'Totais de vendas para a loja **{loja}** por mês')
    plt.xlabel('Mês')
    plt.ylabel('Total de vendas')
    plt.show()


print("Hierarquia das lojas e seus produtos")
for store in np.sort(df['name_store'].unique()):
    print("├──>",store)
    for produto in  np.sort(df['productmodel_name'][df['name_store']==store].unique()):
        print("│  ├───>", produto)        
    


df['productmodel_name'].unique()





df['productmodel_name'] = df['productmodel_name'].str.replace("'", "")


df['productmodel_name'] = df['productmodel_name'].str.replace(" ", "_")


df['productmodel_name'] = df['productmodel_name'].str.replace("/", "--")


df['productmodel_name'].unique()


print(df.columns)


Y_df = df.copy()
Y_df.head()


# Convertendo o nome das colunas para o nome que a biblioteca espera
Y_df = Y_df.rename({'total_qtd_product': 'y', 'orderdate': 'ds','productmodel_name':'product','name_store':'store'}, axis=1)
# Adicionando o nível de hierarquia maior, o país
Y_df.insert(0, 'Total', 'Total')



Y_df.reset_index(drop=True, inplace=True)


Y_df.head()


print(Y_df.columns)


Y_df = Y_df[['Total', 'ds', 'y', 'store','product']]


Y_df.info()


Y_df.head()



Y_df.columns


spec = [
    ['Total'],
    ['Total','store'],
    ['Total','store', 'product']
]


# Criando novos dataframes S_df e tags que são especificações da hierarquia com a função aggregate
Y_df, S_df, tags = aggregate(Y_df, spec)


Y_df.head()


Y_df = Y_df.reset_index()


Y_df.head()


S_df.head()


tags





# Utilizando os 3 últimos meses
horizon = 91

# Ordenando os dados por 'unique_id' e 'ds'
Y_df = Y_df.sort_values(by=['unique_id', 'ds'])

# Selecionando os últimos 91 dias para teste e o restante para treino
Y_test_df = Y_df.groupby('unique_id').tail(horizon)
Y_test_df = Y_test_df.set_index('unique_id')

Y_train_df = Y_df.iloc[:-horizon]
Y_train_df = Y_train_df.set_index('unique_id')
# Calculando as previsões utilizando o modelo ARIMA
fcst = StatsForecast(df=Y_train_df,
                     models=[AutoARIMA(season_length=365), Naive()],
                     freq='D', n_jobs=-1)
Y_hat_df = fcst.forecast(horizon)


Y_train_df.head()


Y_train_df.index


S_df.index


Y_hat_df.index


# Métodos de reconciliação
reconcilers = [
    BottomUp(),
    TopDown(method='forecast_proportions'),
    MiddleOut(middle_level='Total/store',
              top_down_method='forecast_proportions')
]
hrec = HierarchicalReconciliation(reconcilers=reconcilers)
Y_rec_df = hrec.reconcile(Y_hat_df=Y_hat_df, Y_df=Y_train_df,
                          S=S_df, tags=tags)


def mse(y, y_hat):
    return np.mean((y-y_hat)**2)



evaluator = HierarchicalEvaluation(evaluators=[mse])



evaluator.evaluate(Y_rec_df,
                   Y_test_df,
                   tags,
                   "Naive"
                  )


Y_test_df.head()


Y_test_df.shape


Y_train_df.head()


Y_train_df.shape


S_df.head()


S_df.shape


Y_rec_df.head()


Y_rec_df.shape


Y_hat_df.head()


Y_hat_df.shape











%whos


def mse(y, y_hat):
    return np.mean((y-y_hat)**2)


evaluator = HierarchicalEvaluation(evaluators=[mse])
evaluator.evaluate(Y_hat_df=Y_rec_df, Y_test=Y_test_df.set_index('unique_id'),
                   tags=tags, benchmark='Naive')






